---
title: 统计模型（译文）
author: 大鹏
summary: "dapeng 按：本文由 dapeng 译自 Crawley 所著的 _The R Book_ 。yangliufr 提醒这可能造成侵权，故2013年4月发布之后就删除了。到现在（2016年1月）已经过去了快三年，其间有很多朋友来信，提出的问题很多都能在本文中找到答案。所以，我再次贴出来，如有侵权，请告知我，我会迅速处理。"
type: post
date: 2013-04-24T07:10:53+00:00
url: /archives/15283
duoshuo_thread_id:
  - 1360835854884405574
views:
  - 45
categories:
  - 未分类
tags:
  - R

---
dapeng 按：本文由 dapeng 译自 Crawley 所著的 _The R Book_ 。yangliufr 提醒这可能造成侵权，故2013年4月发布之后就删除了。到现在（2016年1月）已经过去了快三年，其间有很多朋友来信，提出的问题很多都能在本文中找到答案。所以，我再次贴出来，如有侵权，请告知我，我会迅速处理。

统计工作中最艰难的部分就要开始了。这即将开始的最艰难部分之一，是选择正确的统计分析方法。而如何选择，取决于你数据的性质和你想要回答的具体问题。关键在于，应当理解你有哪种 _响应_ 变量，以及了解你的 _解释_ 变量的性质。响应变量是你要处理的东西，它的变化正是你所试图了解的，它是作图时处在 _y_ 轴的变量。而解释变量则处于 _x_ 轴。你感兴趣的是，响应变量的变化与解释变量的变化关联到何种程度。你也需要考虑你分析的变量是以何种 _方法_ 来测量它们的测量目标的。一种连续的测量，例如高度和重量，是一个可能得到任何实数值的变量。一个分类变量则是具有两个或更多水平的因子：性别是具有两个水平的因子（男和女），而颜色可能是一个具有七个水平的因子（红橙黄绿蓝靛紫）。

因此，从本质上来说，你要回答下列问题：

  * 你的哪个变量是响应变量？
  * 哪个是解释变量？
  * 解释变量是连续的，还是分类的，或者是两者兼具？
  * 你有哪种响应变量？它是连续的测量，还是计数，还是比例，还是死亡时间，或者是分类？

这些简单的要点将引导你找到合适的统计方法：

**解释变量**

( a ) 所有的解释变量都是连续的 **回归**

( b ) 所有的解释变量都是分类的 **方差分析 (ANOVA)**

( c ) 解释变量既是连续的也是分类的 **方差分析 (ANCOVA)**

**响应变量**

( a ) 连续 **普通回归，ANOVA 或 ANCOVA**

( b ) 比例 **逻辑回归**

( c ) 计数 **对数-线性模型**

( d ) 二项式 **二元逻辑分析**

( e ) 死亡时间 **存活分析**

我们的目标是在一个特定模型中确定参数的值，从而使得到的模型能够 _最优地拟合数据_ 。数据是不可动摇的，它们告诉我们在给定的一套环境下实际发生了什么。常犯的错误是说“数据与模型吻合”，听起来好像数据是种灵活的东西，而我们对模型的结构有清晰的了解似的。恰恰相反，我们要寻找的是用来描述数据的最小充分模型。模型要与数据吻合，而不是相反。最优模型产生的无法解释的变异应当比其他模型都要小（最小残余度），其约束条件是模型中所有参数应当在统计意义上有显著性。

你必须阐明这个模型。它包含着你对解释变量及其与响应变量关联方式的理解。你希望模型是最简单的，这是因为吝啬原理；你也希望模型是充分的，这是因为保留一个无法描述数据变异显著部分的模型是没有意义的。尤为重要的是，要理解 _模型不止一个_ 。这是在传统回归和方差分析中经常隐藏的错误之一。带着这样的错误，同样的模型经常不加批判地被一次又一次使用。大多数情况下，会存在大量不同的模型，或多或少有其合理性，都可以拟合任何给出的数据。如果可能的模型中有充分模型的话，那么数据分析的部分工作就是确定哪些是充分的，然后在这些充分模型中确定哪个是最小充分模型。某些情况下，最优模型可能不止一个，可能一系列不同的模型都可以把数据描述得足够好（或者一样糟，如果离散性很大的话）。

## 最大似然

当我们说起参数值应该提供“模式对数据的最优拟合”的时候，这到底意味着什么？我们采用的惯例是，我们的方法应得到**无偏的、方差最小化的估计**。我们把“最优”定义为**最大似然**。这个观点可能不为人所熟悉，因此值得花一些时间研究来得到一些感性认识。它是这样进行的：

  * 给定数据，
  * 给定我们对模式的选择，
  * 模式参数的何种取值让观测数据最有可能出现？

我们判断模型的基础是，假如模型是正确的，那么观测数据有多大可能性出现。

## 吝啬原理（奥卡姆剃刀）

贯穿本书最重要的主题之一是模型的简化。吝啬原理可以追溯到 14 世纪早期英国 唯名论哲学家奥卡姆的威廉（William of Occam），他坚持认为，对给定的现象，如果存在多种解释方法并且它们解释得同样好，那么 _正确的解释方法应该是最简单的那个_ 。这个观点被称为奥卡姆剃刀，是因为他把解释方法给“剃”到了最简：他的重点在于，解释一件事情并不需要不必要的假设。特别地，为了达到解释的目的，如果不 _知道_ 有的东西是否存在，那就不应假定其存在，除非确实需要。对统计模型来说，吝啬原理意味着：

  * 模型的参数要尽可能地少；
  * 与非线性模型相比，优先选择线性模型；
  * 与大量假设相比，优先选择依靠少量假设的实验；
  * 模型应当简化到 _最小充分_ 为止；
  * 与复杂的解释方法相比，优先选择简单的解释方法。

模型简化的过程是用 R 进行假设检验不可或缺的一部分。一般来说， _只有当一个变量从当前模型中去除后会导致偏差的显著增加时_ ，这个变量才被保留在模型中。寻求简朴，并质疑之（译者注：英国数学家和哲学家怀海德名言）。

然而，当我们热情地对模式进行简化时，我们必须小心，不要在倒掉浴缸水的时候把孩子也倒掉了。爱因斯坦曾为奥卡姆剃刀做了一个独特而精妙的改动。他说：“模型应尽可能简单。但要适可而止。”还要记住奧斯卡·王尔德 （Oscar Wilde ）说过的话：“真理很少纯粹，也绝不简单。”

## 统计模型的类型

用模型来拟合数据是 R 的核心功能。 这个过程在本质上是一种探索。没有固定的规则和绝对的东西。这个过程的目标是，从大量潜在的可以用来描述给定数据的模型中，确定一个最小充分模型（见表9.1）。本书中我们讨论五种模型：

  * 零模型；
  * 最小充分模型；
  * 当前模型；
  * 最大模型；以及
  * 饱和模型。

从饱和模型（或最大模型，两种名称皆可）开始，通过一系列的简化，而得到最小充分模型，这个逐步进行的过程建立在 _删除检验_ 的基础上。这就是 F 检验或卡方检验，用来获取当一个指定项从当前模式中去除而导致偏差增大时的显著性。

[原文链接](http://dapengde.com/archives/15283)

